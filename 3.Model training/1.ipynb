{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client['new_db']\n",
    "presentation_collection = db['presentation_news']\n",
    "stock_ticker_presentation_collection = db['stock_ticker_presentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "presentation_data_list = list(presentation_collection.find())\n",
    "stock_ticker_data_list = list(stock_ticker_presentation_collection.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stock_ticker_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker_list  = []\n",
    "for stock in stock_ticker_data_list:\n",
    "    # stock_data = stock[1]\n",
    "    for key, value in stock.items():\n",
    "        ticker_list.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson import ObjectId\n",
    "final_ticker_list = [ticker_name for ticker_name in ticker_list if not isinstance(ticker_name, ObjectId)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WCIL.NS',\n",
       " 'CELLO.NS',\n",
       " 'COALINDIA.NS',\n",
       " 'PRICOLLTD.NS',\n",
       " 'SHIVATEX.NS',\n",
       " 'EICHERMOT.NS',\n",
       " 'RITESHIN.BO',\n",
       " 'GEOJITFSL.NS',\n",
       " 'RAILTEL.NS',\n",
       " 'SIGNATURE.NS',\n",
       " 'SKYGOLD.NS',\n",
       " 'GOACARBON.BO',\n",
       " 'LT.NS',\n",
       " 'SUNPHARMA.NS',\n",
       " 'PGIL.NS',\n",
       " 'APLAPOLLO.NS',\n",
       " 'KPIL.NS',\n",
       " 'POLYCAB.NS',\n",
       " 'METROBRAND.BO',\n",
       " 'LUPIN.NS',\n",
       " 'SHRIRAMPPS.NS',\n",
       " 'JUBLFOOD.NS',\n",
       " 'ITC.NS',\n",
       " 'WAAREEENER.BO',\n",
       " 'ICICIPRULI.BO',\n",
       " 'SUZLON.NS',\n",
       " 'IPCALAB.NS',\n",
       " 'KEI.NS',\n",
       " 'WELSPUNLIV.NS',\n",
       " 'JSWENERGY.NS',\n",
       " 'MAZDOCK.BO',\n",
       " 'HOMEFIRST.NS',\n",
       " 'JSWINFRA.BO',\n",
       " 'PETRONET.NS',\n",
       " 'INDUSINDBK.NS',\n",
       " 'EPACK.NS',\n",
       " 'RAYMONDLSL.NS',\n",
       " 'HDFCBANK.NS',\n",
       " 'RAYMONDLSL.NS',\n",
       " 'PANACEABIO.NS',\n",
       " 'BPCL.NS',\n",
       " 'RAMKY.BO',\n",
       " 'HGINFRA.NS',\n",
       " 'VEDL.NS',\n",
       " 'LT.NS',\n",
       " 'HGINFRA.NS',\n",
       " 'HAL.NS',\n",
       " 'PNBHOUSING.BO',\n",
       " 'HDFCBANK.NS',\n",
       " 'NTPCGREEN.BO',\n",
       " 'AUROPHARMA.NS',\n",
       " 'IBN',\n",
       " 'AVANTIFEED.NS',\n",
       " 'ANANTRAJ.BO',\n",
       " 'DEVYANI.BO',\n",
       " 'JSWINFRA.BO',\n",
       " 'TATAMOTORS.NS',\n",
       " 'SPICEJET.BO',\n",
       " 'MTARTECH.NS',\n",
       " 'ZODIAC.NS',\n",
       " 'LUMAXTECH.BO',\n",
       " 'SPICEJET.BO',\n",
       " 'MTARTECH.NS',\n",
       " 'ZODIAC.NS',\n",
       " 'LUMAXTECH.BO',\n",
       " 'BHARTIHEXA.NS',\n",
       " 'PIIND.BO',\n",
       " 'STOVEKRAFT.BO',\n",
       " 'SWIGGY.NS',\n",
       " 'GODREJIND.BO',\n",
       " 'RDY',\n",
       " 'AWFIS.NS',\n",
       " 'AUROPHARMA.NS',\n",
       " 'WABAG.NS',\n",
       " 'SBIN.NS',\n",
       " 'COALINDIA.NS',\n",
       " 'EXIDEIND.BO',\n",
       " 'DIXON.BO',\n",
       " 'ASHOKLEY.NS',\n",
       " 'NCC.NS',\n",
       " 'TEXRAIL.BO',\n",
       " 'TATAPOWER.NS',\n",
       " 'CELLO.BO',\n",
       " 'BANKBETF.NS',\n",
       " 'POLYCAB.NS',\n",
       " 'PERSISTENT.NS',\n",
       " 'AFCONS.BO',\n",
       " 'PREMEXPLN.NS',\n",
       " 'CRISIL.NS',\n",
       " 'BANKBETF.NS',\n",
       " 'ASHOKLEY.NS',\n",
       " 'IBN',\n",
       " 'JSFB.NS',\n",
       " 'BAJFINANCE.NS',\n",
       " 'ASTRAMICRO.NS',\n",
       " 'CEATLTD.NS',\n",
       " 'POWERMECH.BO',\n",
       " 'TRIVENI.NS',\n",
       " 'CEATLTD.NS',\n",
       " 'BAJFINANCE.NS',\n",
       " 'AUBANK.BO',\n",
       " 'METROPOLIS.NS',\n",
       " 'ACMESOLAR.NS',\n",
       " 'SHRIPISTON.NS',\n",
       " 'GODREJCP.BO',\n",
       " 'BEL.NS',\n",
       " 'GODREJCP.BO',\n",
       " 'GLAND.BO',\n",
       " 'HEROMOTOCO.NS',\n",
       " 'NTPCGREEN.BO',\n",
       " 'BAJFINANCE.NS',\n",
       " 'DELHIVERY.BO',\n",
       " 'BAJFINANCE.NS',\n",
       " 'HEROMOTOCO.NS',\n",
       " 'VOLTAS.NS',\n",
       " 'CANFINHOME.NS',\n",
       " 'METROPOLIS.NS',\n",
       " 'CERA.NS',\n",
       " 'MANAPPURAM.NS',\n",
       " 'GOKEX.BO',\n",
       " 'HEROMOTOCO.NS',\n",
       " 'BEL.NS',\n",
       " 'INFY',\n",
       " 'TATAPOWER.NS',\n",
       " 'HEROMOTOCO.NS',\n",
       " 'TATAPOWER.NS',\n",
       " 'EUREKAFORB.NS',\n",
       " 'SUPREMEIND.NS',\n",
       " 'HCLTECH.NS',\n",
       " 'KPITTECH.NS',\n",
       " 'SONATSOFTW.NS',\n",
       " 'HDFCBANK.NS',\n",
       " 'JYOTHYLAB.NS',\n",
       " 'SURAJEST.NS',\n",
       " 'EIHOTEL.NS',\n",
       " 'TORNTPHARM.NS',\n",
       " 'IWEL.NS',\n",
       " 'LEMONTREE.BO',\n",
       " 'M&M.NS',\n",
       " 'HAL.NS',\n",
       " 'NETWEB.NS',\n",
       " 'RVNL.NS',\n",
       " 'HGINFRA.NS',\n",
       " 'DIXON.BO',\n",
       " 'CIPLA.NS',\n",
       " 'DIXON.BO',\n",
       " 'HAL.NS',\n",
       " 'M&M.NS',\n",
       " 'HGINFRA.NS',\n",
       " 'NETWEB.NS',\n",
       " 'HATSUN.NS',\n",
       " 'RBLBANK.NS',\n",
       " '000751.SZ',\n",
       " 'RVNL.NS',\n",
       " 'FLUOROCHEM.BO',\n",
       " 'PRICOLLTD.NS',\n",
       " 'SOLARINDS.BO',\n",
       " 'BAJFINANCE.NS',\n",
       " 'SOLARINDS.BO',\n",
       " 'ANANTRAJ.BO',\n",
       " 'RBLBANK.NS',\n",
       " 'KPIGREEN.NS',\n",
       " 'RBLBANK.NS',\n",
       " '000751.SZ',\n",
       " 'BAJFINANCE.NS',\n",
       " '000751.SZ',\n",
       " 'BRIGADE.NS',\n",
       " 'NYKAA.NS',\n",
       " 'NTPCGREEN.BO',\n",
       " 'ITC.NS',\n",
       " 'SHIVATEX.NS',\n",
       " 'RADICO.NS',\n",
       " 'WCIL.NS',\n",
       " '0P0001HCLR.BO',\n",
       " 'COALINDIA.NS',\n",
       " 'CELLO.NS',\n",
       " 'SIGNATURE.NS',\n",
       " 'PRICOLLTD.NS',\n",
       " 'RITESHIN.BO',\n",
       " 'EICHERMOT.NS',\n",
       " 'RADICO.NS']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ticker_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(presentation_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "<h3>Taking historical data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'WCIL.NS': [0.24520364 0.39925635 0.13053077 0.61538465 0.0697574  0.86128406\n",
      " 0.92685906 0.23682762 0.95212294 0.28251007 0.95847077 0.93948136\n",
      " 0.51406995 0.66161203 0.95780376 0.45381559]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "stock_tickers = final_ticker_list.copy()\n",
    "\n",
    "embedding_dim = 16  \n",
    "\n",
    "stock_embeddings = {}\n",
    "\n",
    "for ticker in stock_tickers:\n",
    "    stock_embeddings[ticker] = np.random.rand(embedding_dim)\n",
    "\n",
    "\n",
    "print(f\"Embedding for 'WCIL.NS': {stock_embeddings['WCIL.NS']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0.31149451 0.96898494 0.979234   0.13864564 0.17541962 0.51071561\n",
      " 0.81375833 0.57924885 0.68805311 0.61018044 0.73203585 0.18679368\n",
      " 0.49499438 0.52120132 0.24953592 0.60597807]\n"
     ]
    }
   ],
   "source": [
    "print(f\" {stock_embeddings['KPIL.NS']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "def fetch_stock_data(tickers, start_date, end_date):\n",
    "    stock_data = {}\n",
    "    for ticker in tickers:\n",
    "        # print(f\"Fetching data for {ticker}...\")\n",
    "        data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        stock_data[ticker] = data\n",
    "    return stock_data\n",
    "\n",
    "# Example: Fetch data for the last 10 years\n",
    "start_date = \"2014-01-01\"\n",
    "end_date = \"2025-01-01\"\n",
    "data = fetch_stock_data(stock_tickers, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "def preprocess_stock_data(stock_data, sequence_length=30):\n",
    "    scaler = MinMaxScaler()\n",
    "    stock_data_scaled = scaler.fit_transform(stock_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "    \n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(stock_data_scaled)):\n",
    "        X.append(stock_data_scaled[i-sequence_length:i])\n",
    "        y.append(stock_data_scaled[i, 3])  \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\n",
    "sequence_length = 30\n",
    "X_all, y_all, stock_ids = [], [], []\n",
    "for i, ticker in enumerate(stock_tickers):\n",
    "    if ticker in data:\n",
    "        stock_data = data[ticker].dropna()  \n",
    "        X, y = preprocess_stock_data(stock_data, sequence_length)\n",
    "        \n",
    "        if X.shape[0] > 0 and X.ndim == 3 and y.ndim == 1:\n",
    "            X_all.append(X)\n",
    "            y_all.append(y)\n",
    "            stock_ids.extend([i] * len(X))\n",
    "\n",
    "\n",
    "X_all = np.vstack(X_all)\n",
    "y_all = np.hstack(y_all)\n",
    "stock_ids = np.array(stock_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 16\n",
    "stock_embeddings = np.random.rand(len(stock_tickers), embedding_dim)\n",
    "\n",
    "stock_embedding_data = stock_embeddings[stock_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ historical_data     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">17,920</span> │ historical_data[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stock_embedding     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ stock_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ historical_data     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m5\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m17,920\u001b[0m │ historical_data[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ stock_embedding     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ stock_embedding[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m3,136\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,585</span> (139.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m35,585\u001b[0m (139.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">35,585</span> (139.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m35,585\u001b[0m (139.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input\n",
    "\n",
    "# Model Inputs\n",
    "historical_input = Input(shape=(sequence_length, 5), name=\"historical_data\")  # 5 features (OHLCV)\n",
    "embedding_input = Input(shape=(embedding_dim,), name=\"stock_embedding\")\n",
    "\n",
    "# LSTM for Historical Data\n",
    "x = layers.LSTM(64, return_sequences=True)(historical_input)\n",
    "x = layers.LSTM(32)(x)\n",
    "\n",
    "# Combine LSTM output with Stock Embedding\n",
    "x = layers.concatenate([x, embedding_input])\n",
    "x = layers.Dense(64, activation=\"relu\")(x)\n",
    "x = layers.Dense(32, activation=\"relu\")(x)\n",
    "\n",
    "# Output Layer (Regression for 'Close' price)\n",
    "output = layers.Dense(1, activation=\"linear\", name=\"output\")(x)\n",
    "\n",
    "# Model\n",
    "model = models.Model(inputs=[historical_input, embedding_input], outputs=output)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 43ms/step - loss: 0.0020 - mae: 0.0225 - val_loss: 4.0510e-04 - val_mae: 0.0148\n",
      "Epoch 2/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 37ms/step - loss: 2.2117e-04 - mae: 0.0097 - val_loss: 1.6662e-04 - val_mae: 0.0078\n",
      "Epoch 3/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 54ms/step - loss: 1.9946e-04 - mae: 0.0089 - val_loss: 1.6789e-04 - val_mae: 0.0080\n",
      "Epoch 4/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 55ms/step - loss: 1.8531e-04 - mae: 0.0085 - val_loss: 1.5531e-04 - val_mae: 0.0072\n",
      "Epoch 5/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 45ms/step - loss: 1.8455e-04 - mae: 0.0083 - val_loss: 1.5489e-04 - val_mae: 0.0072\n",
      "Epoch 6/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 34ms/step - loss: 1.8342e-04 - mae: 0.0082 - val_loss: 1.5288e-04 - val_mae: 0.0072\n",
      "Epoch 7/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 34ms/step - loss: 1.8248e-04 - mae: 0.0081 - val_loss: 1.6004e-04 - val_mae: 0.0077\n",
      "Epoch 8/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 34ms/step - loss: 1.7800e-04 - mae: 0.0080 - val_loss: 1.5937e-04 - val_mae: 0.0075\n",
      "Epoch 9/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 33ms/step - loss: 1.7816e-04 - mae: 0.0080 - val_loss: 1.5681e-04 - val_mae: 0.0077\n",
      "Epoch 10/10\n",
      "\u001b[1m4347/4347\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 33ms/step - loss: 1.8218e-04 - mae: 0.0080 - val_loss: 1.8326e-04 - val_mae: 0.0089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c8faac9fd0>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, embeddings_train, embeddings_test = train_test_split(\n",
    "    X_all, y_all, stock_embedding_data, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    [X_train, embeddings_train],\n",
    "    y_train,\n",
    "    validation_data=([X_test, embeddings_test], y_test),\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_stock(ticker, model, stock_embeddings, stock_tickers, sequence_length=30):\n",
    "    # Fetch the recent 30 days of data for the ticker\n",
    "    recent_data = yf.download(ticker, period=\"30d\")\n",
    "    recent_data = recent_data.dropna()\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(recent_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
    "    \n",
    "    # Create the input sequence for prediction (last 30 days)\n",
    "    input_sequence = scaled_data[-sequence_length:].reshape(1, sequence_length, 5)  # shape (1, 30, 5)\n",
    "    \n",
    "    # Ensure the stock embedding has the correct shape (1, embedding_dim)\n",
    "    stock_index = stock_tickers.index(ticker)\n",
    "    \n",
    "    # Extract the embedding and check its size\n",
    "    stock_embedding = stock_embeddings[stock_index]\n",
    "    \n",
    "    # Ensure that stock_embedding is a 1D array of size embedding_dim\n",
    "    if stock_embedding.ndim == 1:\n",
    "        stock_embedding = stock_embedding.reshape(1, -1)  # Reshape to (1, embedding_dim)\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"input_sequence shape: {input_sequence.shape}\")\n",
    "    print(f\"stock_embedding shape: {stock_embedding.shape}\")\n",
    "    \n",
    "    # Predict the stock price (Close price)\n",
    "    prediction = model.predict([input_sequence, stock_embedding])\n",
    "    \n",
    "    # De-normalize the prediction (map it back to the original scale)\n",
    "    return scaler.inverse_transform([[0, 0, 0, prediction[0][0], 0]])[0][3]  # De-normalize the 'Close' price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_ticker_to_index = {ticker: idx for idx, ticker in enumerate(stock_tickers)}\n",
    "stock_index = stock_ticker_to_index[\"COALINDIA.NS\"]\n",
    "stock_embedding = stock_embeddings[stock_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_sequence shape: (1, 30, 5)\n",
      "stock_embedding shape: ()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m final \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_stock\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCOALINDIA.NS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfinal_ticker_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(final)\n",
      "Cell \u001b[1;32mIn[162], line 28\u001b[0m, in \u001b[0;36mpredict_stock\u001b[1;34m(ticker, model, stock_embeddings, stock_tickers, sequence_length)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_embedding shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstock_embedding\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Predict the stock price (Close price)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstock_embedding\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# De-normalize the prediction (map it back to the original scale)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scaler\u001b[38;5;241m.\u001b[39minverse_transform([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, prediction[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m]])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m3\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\AjayPatil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\AjayPatil\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\data_adapter_utils.py:103\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_data_cardinality\u001b[39m(data):\n\u001b[1;32m--> 103\u001b[0m     num_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tree\u001b[38;5;241m.\u001b[39mflatten(data))\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(num_samples) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    105\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData cardinality is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         )\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "final = predict_stock(\"COALINDIA.NS\", model, stock_embedding,final_ticker_list)\n",
    "print(final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
