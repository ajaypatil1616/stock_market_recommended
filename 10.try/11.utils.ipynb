{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout, Flatten\n",
    "from keras.preprocessing import LabelEncoder\n",
    "\n",
    "# 1. Encode Tickers using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['ticker_encoded'] = label_encoder.fit_transform(df['ticker'])\n",
    "\n",
    "# 2. Prepare the features (X) and target (y)\n",
    "# X would include features like Open, Close, etc., along with the encoded ticker\n",
    "X = df[['Open', 'High', 'Low', 'Close', 'Volume', 'ticker_encoded']].values\n",
    "y = df['Close']  # Assuming you are predicting 'Close' price\n",
    "\n",
    "# 3. Define LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer for ticker\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=10, input_length=X.shape[1]))\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "# Dense layer for output\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout, Flatten\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Sample data: Replace this with your actual data\n",
    "data = {\n",
    "    'Date': ['2023-11-06', '2023-11-07', '2023-11-08', '2023-11-09', '2023-11-10', '2023-11-13', '2023-11-15'],\n",
    "    'Open': [829.0, 791.3, 803.85, 803.0, 785.0, 794.95, 790.0],\n",
    "    'High': [837.4, 815.6, 812.7, 804.6, 798.7, 795.95, 798.9],\n",
    "    'Low': [782.0, 772.0, 792.1, 778.0, 781.1, 782.2, 780.25],\n",
    "    'Close': [791.7, 799.15, 800.65, 785.2, 789.6, 785.85, 787.45],\n",
    "    'Adj Close': [790.43, 797.87, 799.36, 783.94, 788.33, 784.59, 786.19],\n",
    "    'Volume': [17947726, 4204640, 933907, 631244, 1114462, 373643, 774158],\n",
    "    'ticker': ['CELLO.NS', 'CELLO.NS', 'CELLO.NS', 'CELLO.NS', 'CELLO.NS', 'CELLO.NS', 'CELLO.NS']\n",
    "}\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Label encoding the 'ticker' column\n",
    "label_encoder = LabelEncoder()\n",
    "df['ticker_encoded'] = label_encoder.fit_transform(df['ticker'])\n",
    "\n",
    "# Step 2: Prepare the feature columns (Open, High, Low, Close, Volume) and the encoded ticker\n",
    "X = df[['Open', 'High', 'Low', 'Close', 'Volume', 'ticker_encoded']].values\n",
    "\n",
    "# For the sake of this example, let's assume we're predicting the 'Close' price (this would be your target)\n",
    "y = df['Close'].values\n",
    "\n",
    "# Step 3: Reshape the data for LSTM (samples, time steps, features)\n",
    "# Since this is daily data, we treat each row as a \"time step\". We need to reshape the data accordingly.\n",
    "# LSTM expects a 3D input: (samples, time steps, features)\n",
    "\n",
    "# Here we're assuming each input is 1 time step (i.e., daily data), and the number of features is 6.\n",
    "X = np.reshape(X, (X.shape[0], 1, X.shape[1]))\n",
    "\n",
    "# Step 4: Build the LSTM model\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer for ticker (we assume there are 'n' unique tickers, and we use an embedding dimension of 10)\n",
    "# 'input_dim' is the number of unique tickers, and 'output  _dim' is the size of the dense vector for each ticker.\n",
    "model.add(Embedding(input_dim=len(label_encoder.classes_), output_dim=10, input_length=1))\n",
    "\n",
    "# LSTM layer\n",
    "model.add(LSTM(50, return_sequences=False))\n",
    "\n",
    "# Dense layer to output a single value (e.g., the 'Close' price)\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Step 5: Train the model\n",
    "# Note: This is a small dataset; you would typically train on a larger dataset with more epochs.\n",
    "model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "# Step 6: Predict on new data\n",
    "predictions = model.predict(X)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
