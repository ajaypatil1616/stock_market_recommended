{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ticker_list = ['SBIN.NS',\n",
    "                     'COALINDIA.NS',\n",
    "                     'MOIL.NS'\n",
    "#     'WCIL.NS',\n",
    "#  'CELLO.NS',\n",
    "#  'PRICOLLTD.NS',\n",
    "#  'SHIVATEX.NS',\n",
    "#  'EICHERMOT.NS',\n",
    "#  'RITESHIN.BO',\n",
    "#  'GEOJITFSL.NS',\n",
    "#  'RAILTEL.NS',\n",
    "#  'SIGNATURE.NS',\n",
    "#  'SKYGOLD.NS',\n",
    "#  'GOACARBON.BO',\n",
    "#  'LT.NS',\n",
    "#  'SUNPHARMA.NS',\n",
    "#  'PGIL.NS',\n",
    "#  'APLAPOLLO.NS',\n",
    "#  'KPIL.NS',\n",
    "#  'POLYCAB.NS',\n",
    "#  'METROBRAND.BO',\n",
    "#  'LUPIN.NS',\n",
    "#  'SHRIRAMPPS.NS',\n",
    "#  'JUBLFOOD.NS',\n",
    "#  'ITC.NS',\n",
    "#  'WAAREEENER.BO',\n",
    "#  'ICICIPRULI.BO',\n",
    "#  'SUZLON.NS',\n",
    "#  'IPCALAB.NS',\n",
    "#  'KEI.NS',\n",
    "#  'WELSPUNLIV.NS',\n",
    "#  'JSWENERGY.NS',\n",
    "#  'MAZDOCK.BO',\n",
    "#  'HOMEFIRST.NS',\n",
    "#  'JSWINFRA.BO',\n",
    "#  'PETRONET.NS',\n",
    "#  'INDUSINDBK.NS',\n",
    "#  'EPACK.NS',\n",
    "#  'RAYMONDLSL.NS',\n",
    "#  'HDFCBANK.NS',\n",
    "#  'RAYMONDLSL.NS',\n",
    "#  'PANACEABIO.NS',\n",
    "#  'BPCL.NS',\n",
    "#  'RAMKY.BO',\n",
    "#  'HGINFRA.NS',\n",
    "#  'VEDL.NS',\n",
    "#  'LT.NS',\n",
    "#  'HGINFRA.NS',\n",
    "#  'HAL.NS',\n",
    "#  'PNBHOUSING.BO',\n",
    "#  'HDFCBANK.NS',\n",
    "#  'NTPCGREEN.BO',\n",
    "#  'AUROPHARMA.NS',\n",
    "#  'IBN',\n",
    "#  'AVANTIFEED.NS',\n",
    "#  'ANANTRAJ.BO',\n",
    "#  'DEVYANI.BO',\n",
    "#  'JSWINFRA.BO',\n",
    "#  'TATAMOTORS.NS',\n",
    "#  'SPICEJET.BO',\n",
    "#  'MTARTECH.NS',\n",
    "#  'ZODIAC.NS',\n",
    "#  'LUMAXTECH.BO',\n",
    "#  'SPICEJET.BO',\n",
    "#  'MTARTECH.NS',\n",
    "#  'ZODIAC.NS',\n",
    "#  'LUMAXTECH.BO',\n",
    "#  'BHARTIHEXA.NS',\n",
    "#  'PIIND.BO',\n",
    "#  'STOVEKRAFT.BO',\n",
    "#  'SWIGGY.NS',\n",
    "#  'GODREJIND.BO',\n",
    "#  'RDY',\n",
    "#  'AWFIS.NS',\n",
    "#  'AUROPHARMA.NS',\n",
    "#  'WABAG.NS',\n",
    "#  'SBIN.NS',\n",
    "#  'COALINDIA.NS',\n",
    "#  'EXIDEIND.BO',\n",
    "#  'DIXON.BO',\n",
    "#  'ASHOKLEY.NS',\n",
    "#  'NCC.NS',\n",
    "#  'TEXRAIL.BO',\n",
    "#  'TATAPOWER.NS',\n",
    "#  'CELLO.BO',\n",
    "#  'BANKBETF.NS',\n",
    "#  'POLYCAB.NS',\n",
    "#  'PERSISTENT.NS',\n",
    "#  'AFCONS.BO',\n",
    "#  'PREMEXPLN.NS',\n",
    "#  'CRISIL.NS',\n",
    "#  'BANKBETF.NS',\n",
    "#  'ASHOKLEY.NS',\n",
    "#  'IBN',\n",
    "#  'JSFB.NS',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  'ASTRAMICRO.NS',\n",
    "#  'CEATLTD.NS',\n",
    "#  'POWERMECH.BO',\n",
    "#  'TRIVENI.NS',\n",
    "#  'CEATLTD.NS',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  'AUBANK.BO',\n",
    "#  'METROPOLIS.NS',\n",
    "#  'ACMESOLAR.NS',\n",
    "#  'SHRIPISTON.NS',\n",
    "#  'GODREJCP.BO',\n",
    "#  'BEL.NS',\n",
    "#  'GODREJCP.BO',\n",
    "#  'GLAND.BO',\n",
    "#  'HEROMOTOCO.NS',\n",
    "#  'NTPCGREEN.BO',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  'DELHIVERY.BO',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  'HEROMOTOCO.NS',\n",
    "#  'VOLTAS.NS',\n",
    "#  'CANFINHOME.NS',\n",
    "#  'METROPOLIS.NS',\n",
    "#  'CERA.NS',\n",
    "#  'MANAPPURAM.NS',\n",
    "#  'GOKEX.BO',\n",
    "#  'HEROMOTOCO.NS',\n",
    "#  'BEL.NS',\n",
    "#  'INFY',\n",
    "#  'TATAPOWER.NS',\n",
    "#  'HEROMOTOCO.NS',\n",
    "#  'TATAPOWER.NS',\n",
    "#  'EUREKAFORB.NS',\n",
    "#  'SUPREMEIND.NS',\n",
    "#  'HCLTECH.NS',\n",
    "#  'KPITTECH.NS',\n",
    "#  'SONATSOFTW.NS',\n",
    "#  'HDFCBANK.NS',\n",
    "#  'JYOTHYLAB.NS',\n",
    "#  'SURAJEST.NS',\n",
    "#  'EIHOTEL.NS',\n",
    "#  'TORNTPHARM.NS',\n",
    "#  'IWEL.NS',\n",
    "#  'LEMONTREE.BO',\n",
    "#  'M&M.NS',\n",
    "#  'HAL.NS',\n",
    "#  'NETWEB.NS',\n",
    "#  'RVNL.NS',\n",
    "#  'HGINFRA.NS',\n",
    "#  'DIXON.BO',\n",
    "#  'CIPLA.NS',\n",
    "#  'DIXON.BO',\n",
    "#  'HAL.NS',\n",
    "#  'M&M.NS',\n",
    "#  'HGINFRA.NS',\n",
    "#  'NETWEB.NS',\n",
    "#  'HATSUN.NS',\n",
    "#  'RBLBANK.NS',\n",
    "#  '000751.SZ',\n",
    "#  'RVNL.NS',\n",
    "#  'FLUOROCHEM.BO',\n",
    "#  'PRICOLLTD.NS',\n",
    "#  'SOLARINDS.BO',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  'SOLARINDS.BO',\n",
    "#  'ANANTRAJ.BO',\n",
    "#  'RBLBANK.NS',\n",
    "#  'KPIGREEN.NS',\n",
    "#  'RBLBANK.NS',\n",
    "#  '000751.SZ',\n",
    "#  'BAJFINANCE.NS',\n",
    "#  '000751.SZ',\n",
    "#  'BRIGADE.NS',\n",
    "#  'NYKAA.NS',\n",
    "#  'NTPCGREEN.BO',\n",
    "#  'ITC.NS',\n",
    "#  'SHIVATEX.NS',\n",
    "#  'RADICO.NS',\n",
    "#  'WCIL.NS',\n",
    "#  'COALINDIA.NS',\n",
    "#  'CELLO.NS',\n",
    "#  'SIGNATURE.NS',\n",
    "#  'PRICOLLTD.NS',\n",
    "#  'RITESHIN.BO',\n",
    "#  'EICHERMOT.NS',\n",
    "#  'RADICO.NS'\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding, Input, Concatenate, Dropout, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 60\n",
    "feature_columns = ['Open', 'High', 'Low', 'Close', 'Volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(ticker_list):\n",
    "    all_data = []\n",
    "    for ticker in ticker_list:\n",
    "        try:\n",
    "            stock_data = yf.download(ticker, period=\"max\")\n",
    "            first_date = stock_data.index.min()\n",
    "    \n",
    "            ideal_start_date = pd.to_datetime('2010-01-01')\n",
    "            start_date = ideal_start_date if first_date < ideal_start_date else first_date\n",
    "            \n",
    "            data = yf.download(ticker, start=start_date, end=\"2025-01-01\")\n",
    "            data['ticker'] = ticker\n",
    "            all_data.append(data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {ticker}: {e}\")\n",
    "    \n",
    "    \n",
    "    all_data_df = pd.concat(all_data)\n",
    "    \n",
    "    # Reseting  index to make the date a column in the DataFrame\n",
    "    all_data_df.reset_index(inplace=True)\n",
    "    \n",
    "    return all_data_df\n",
    "\n",
    "\n",
    "ticker_list = list(set(final_ticker_list)) \n",
    "print(\"Fetching data...\")\n",
    "data = fetch_data(ticker_list)\n",
    "\n",
    "\n",
    "data.to_csv(\"raw_stock_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_combined_data(data):\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    data['ticker_encoded'] = label_encoder.fit_transform(data['ticker'])\n",
    "\n",
    "    scalers = {}\n",
    "\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    tickers = []\n",
    "\n",
    "    for ticker, group in data.groupby('ticker_encoded'):\n",
    "        \n",
    "        group = group.sort_values('Date')\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        scaled_features = scaler.fit_transform(group[feature_columns])\n",
    "        scalers[ticker] = scaler  \n",
    "\n",
    "        \n",
    "        for i in range(lookback, len(group)):\n",
    "            seq = scaled_features[i - lookback:i]\n",
    "            target = group['Close'].iloc[i]  \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "            tickers.append(ticker)\n",
    "\n",
    "    X = np.array(sequences)\n",
    "    y = np.array(targets)\n",
    "\n",
    "   \n",
    "    ticker_to_int = {ticker: idx for idx, ticker in enumerate(label_encoder.classes_)}\n",
    "    \n",
    "    return X, y, ticker_to_int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "processed_data = pd.DataFrame(X.reshape(-1, X.shape[2])) \n",
    "\n",
    "\n",
    "processed_data['target'] = np.repeat(y, lookback)  \n",
    "\n",
    "\n",
    "ticker_column = np.repeat(data['ticker_encoded'].values, lookback)\n",
    "if len(ticker_column) != len(processed_data):\n",
    "    ticker_column = ticker_column[:len(processed_data)]  \n",
    "\n",
    "processed_data['ticker'] = ticker_column\n",
    "\n",
    "\n",
    "processed_data.to_csv(\"processed_stock_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])  \n",
    "model = create_lstm_model(input_shape)\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(\"Training the LSTM model...\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "model.save(\"lstm_stock_model.h5\")\n",
    "print(\"Model saved as 'lstm_stock_model.h5'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss, mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Fetch the last 'lookback' days of data\n",
    "def fetch_recent_data(ticker, lookback=60):\n",
    "    stock_data = yf.download(ticker, period=\"90d\")  # Fetch the last 90 days for safety\n",
    "    stock_data = stock_data.tail(lookback)  # Get the last 'lookback' rows\n",
    "    return stock_data\n",
    "\n",
    "# Preprocess the data for prediction\n",
    "def preprocess_for_prediction(data, feature_columns, scaler):\n",
    "    scaled_features = scaler.transform(data[feature_columns])\n",
    "    return scaled_features\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"./lstm_stock_model.h5\")\n",
    "\n",
    "# Fetch recent data for COALINDIA.NS\n",
    "ticker = \"COALINDIA.NS\"\n",
    "recent_data = fetch_recent_data(ticker, lookback=lookback)\n",
    "\n",
    "# Ensure 'recent_data' contains all required feature columns\n",
    "if set(feature_columns).issubset(recent_data.columns):\n",
    "    # Initialize scaler for COALINDIA.NS\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(recent_data[feature_columns])  # Refit scaler based on recent data\n",
    "    \n",
    "    # Prepare input sequence\n",
    "    input_sequence = preprocess_for_prediction(recent_data, feature_columns, scaler)\n",
    "    input_sequence = input_sequence.reshape(1, lookback, len(feature_columns))  # Shape (1, lookback, features)\n",
    "    \n",
    "    # Predict the next day's price\n",
    "    next_day_scaled = model.predict(input_sequence)[0][0]\n",
    "    \n",
    "    # Inverse scale to get the actual price\n",
    "    next_day_price = scaler.inverse_transform([[0, 0, 0, next_day_scaled, 0]])[0][3]  # Only inverse 'Close'\n",
    "    \n",
    "    print(f\"Predicted price for {ticker} on the next day: {next_day_price:.2f}\")\n",
    "else:\n",
    "    print(\"Error: Recent data is missing required feature columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
